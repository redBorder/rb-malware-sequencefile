package net.redborder.malware.sequencefile.managers;

import net.redborder.clusterizer.NotifyListener;
import net.redborder.malware.sequencefile.SequenceFile;
import net.redborder.malware.sequencefile.peons.SequencePeon;
import net.redborder.malware.sequencefile.util.ConfigFile;
import org.apache.curator.RetryPolicy;
import org.apache.curator.framework.CuratorFramework;
import org.apache.curator.framework.CuratorFrameworkFactory;
import org.apache.curator.framework.imps.CuratorFrameworkState;
import org.apache.curator.framework.recipes.barriers.DistributedBarrier;
import org.apache.curator.framework.recipes.locks.InterProcessSemaphoreMutex;
import org.apache.curator.retry.ExponentialBackoffRetry;
import org.apache.log4j.Logger;
import org.codehaus.jackson.map.ObjectMapper;

import java.util.*;
import java.util.concurrent.ConcurrentLinkedQueue;


/**
 * Created by andresgomez on 3/2/15.
 */
public class SequenceManager extends Thread implements NotifyListener {

    private Queue<SequencePeon> peons;
    private static SequenceManager theInstance = null;
    Object monitor = new Object();
    CuratorFramework client;
    Map<String, Object> maps;
    ObjectMapper mapper;
    InterProcessSemaphoreMutex mutex;
    DistributedBarrier barrierSeqOozie;
    SequenceManager.Status status = Status.CLOSE;
    private static final Logger log = Logger.getLogger(SequenceManager.class);
    private static String mode;
    private static String LOGSTASH_PATH;

    enum Status {
        INIT, RUNNING, CLOSING, CLOSE
    }


    private SequenceManager() {
        init();
    }
    
    private SequenceManager(String LOGSTASH_PATH) {
    	this();
        SequenceManager.LOGSTASH_PATH = LOGSTASH_PATH;
    }

    public synchronized static SequenceManager getInstance() {
        if (theInstance == null) {
        	theInstance = new SequenceManager();
        }
        return theInstance;
    }
    
    public synchronized static SequenceManager getInstance(String LOGSTASH_PATH) {
        if (theInstance == null) {
        	theInstance = new SequenceManager(LOGSTASH_PATH);
        }
        return theInstance;
    }

    private void init() {
        status = Status.INIT;
        log.trace("At init method");
        log.info("Status [" + status.name() + "]");
        mapper = new ObjectMapper();
        mode = (String) ConfigFile.getInstance().getFromGeneral("mode","hadoop");
        RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);
        client = CuratorFrameworkFactory.newClient(ConfigFile.getInstance().getZkConnect(), retryPolicy);
        client.start();

        // List of peons
        peons = new ConcurrentLinkedQueue<>();

        // create new Semaphore
        mutex = new InterProcessSemaphoreMutex(client, "/rb_malware/sequence-file/mutex");
        if (mode.equals("hadoop")) {
	        // create new barrier
	        barrierSeqOozie = new DistributedBarrier(client, "/rb_malware/seq-oozie/seq_must_wait");
        }
    }

    @Override
    public void run() {
        log.trace("At run method");
        status = Status.RUNNING;
        log.info("Status [" + status.name() + "]");
        if (!client.getState().equals(CuratorFrameworkState.STARTED)) {
            try {
                // Wait 5 seconds
                Thread.sleep(5000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }

        // While thread is running or closing
        while (status.equals(Status.RUNNING) || status.equals(Status.CLOSING)) {
            log.trace("Before waitTasks");
            // Wait for tasks (Blocking thread here!)
            waitTasks();
            log.trace("After waitTasks");
            List<String> hdfsSeqFiles = new ArrayList<>();

            // We wait until all peons end up
            SequencePeon peon;

            // Extract and remove peon from queue (if exists)
            while ((peon = peons.poll()) != null) {
                try {
                    log.trace("Peon join");

                    // Start when other thread finish
                    peon.join();

                    if (mode.equals("hadoop")) {
	                    // Get the HDFS file and add to list
	                    hdfsSeqFiles.add(peon.getHdfsFile());
	                    log.trace("SequenceFile ready to send to oozieLeader");
                    }
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            if (mode.equals("hadoop")) {
	            // If exist almost file
	            for (String file : hdfsSeqFiles) {
	                //We send a sequence file to OozieLeader using /rb_malware/oozie/task
	                try {
	                    log.trace("WaitingOnBarrier");
	                    barrierSeqOozie.waitOnBarrier();
	                    barrierSeqOozie.setBarrier();
	                    log.trace("Barrier set");
	                    String taskName = UUID.randomUUID().toString();
	                    log.trace("Writing OozieTask at ZK");
	                    client.create().forPath("/rb_malware/oozie/tasks/" + taskName, file.getBytes());
	                } catch (Exception e) {
	                    e.printStackTrace();
	                }
	            }
            }

            if (status.equals(Status.CLOSING)) {
                status = Status.CLOSE;
                client.close();
                log.info("Status [" + status.name() + "]");
            }
        }
    }


    @Override
    public void time2Work() {

            log.trace("At time2Work method");
            if (status.equals(Status.RUNNING) || status.equals(Status.CLOSING)) {
                try {
                    log.debug("The client status is: "+client.getState());
                    List<String> childrens = client.getChildren().forPath("/rb_malware/sequence-file/tasks");

                    if (!childrens.isEmpty()) {
                        String children;
                        try {
                            mutex.acquire();
                            children = childrens.get(0);
                            byte[] zkData = client.getData().forPath("/rb_malware/sequence-file/tasks/" + children);
                            maps = (Map<String, Object>) mapper.readValue(zkData, Map.class);
                            log.trace("Taking task");
                            client.delete().forPath("/rb_malware/sequence-file/tasks/" + children);
                            mutex.release();
                        } catch (Exception e) {
                            e.printStackTrace();
                        }
                        SequencePeon peon = null;
                        SequenceFile sequenceFile = new SequenceFile(maps);
                        log.trace("Starting peon");
                        
                        if (mode.equals("hadoop")) {peon = new SequencePeon(sequenceFile);} 
                        else if (mode.equals("logstash")) {peon = new SequencePeon(sequenceFile, LOGSTASH_PATH);}
                        
                        peon.start();
                        peons.add(peon);
                        
                        log.trace("NotifyTask");
                        notifyTask();
                        
                    }else{
                        log.trace("time2Work has been called but there aren't available tasks");
                    }
                } catch (Exception e) {
                    log.info(e.getMessage());
                }
            }
    }

    public void notifyTask() {
        synchronized (monitor) {
            monitor.notifyAll();
        }
    }

    public void waitTasks() {
        try {
            synchronized (monitor) {
                // Wait here!
                monitor.wait();

                log.debug("Sequence Manager running");
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

    public void close() {
        status = Status.CLOSING;
        notifyTask();
        log.info("Status [" + status.name() + "]");
    }
}
