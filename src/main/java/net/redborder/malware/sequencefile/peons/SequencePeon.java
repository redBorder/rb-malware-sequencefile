package net.redborder.malware.sequencefile.peons;

import net.redborder.malware.sequencefile.SequenceFile;
import net.redborder.malware.sequencefile.util.ConfigFile;
import net.redborder.malware.sequencefile.util.logger.RbLogger;
import org.apache.commons.codec.digest.DigestUtils;
import org.apache.commons.io.IOUtils;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.Text;

import org.jets3t.service.S3Service;

import org.jets3t.service.impl.rest.httpclient.RestS3Service;
import org.jets3t.service.model.S3Object;
import org.jets3t.service.model.StorageObject;

import org.jets3t.service.security.AWSCredentials;
import org.joda.time.DateTime;



import java.io.IOException;
import java.util.List;

import java.util.logging.Level;
import java.util.logging.Logger;

/**
 * Created by andresgomez on 3/2/15.
 */
public class SequencePeon extends Thread {
    private Logger log = null;
    S3Service s3Service;
    SequenceFile seq;
    String hdfsURL;

    private static final String SEQUENCE_FILE_PATH = "hdfs://hadoopnamenode.redborder.cluster:8020/user/oozie/sequence_file";


    public SequencePeon(SequenceFile seq){
        this.seq = seq;
        AWSCredentials awsCredentials = new AWSCredentials((String) ConfigFile.getInstance().getFromGeneral("aws_access"), (String) ConfigFile.getInstance().getFromGeneral("aws_secret"));
        s3Service = new RestS3Service(awsCredentials);
    }

    @Override
    public void run() {
        log = RbLogger.getLogger(SequencePeon.class.getName() + Thread.currentThread().getId(), String.valueOf(Thread.currentThread().getId()));
        System.out.println("Launching sequence peon [" + Thread.currentThread().getId() +"]");
        Configuration conf =  new Configuration();
        conf.set("fs.hdfs.impl",
                org.apache.hadoop.hdfs.DistributedFileSystem.class.getName()
        );
        conf.addResource("/opt/rb/var/hadoop/etc/hadoop/core-site.xml");
        conf.addResource("/opt/rb/var/hadoop/share/doc/hadoop/hadoop-project-dist/hadoop-common/core-default.xml");
        DateTime date = new DateTime();
        String path = SEQUENCE_FILE_PATH + "/" + date.getYear() + "/" + date.getMonthOfYear() + "/" + date.getDayOfMonth() + "/" + date.getHourOfDay();


        Long timestamp = System.currentTimeMillis();
        String hash = DigestUtils.md5Hex(seq.getS3FilesPaths().toString().getBytes());
        String fileKey = timestamp +"-"+hash+".seq";
        Path name = new Path(path + "/" + fileKey);
        org.apache.hadoop.io.SequenceFile.Writer writer = null;
        try {
            org.apache.hadoop.io.SequenceFile.Writer.Option filePath =  org.apache.hadoop.io.SequenceFile.Writer.file(name);
            org.apache.hadoop.io.SequenceFile.Writer.Option keyClass =  org.apache.hadoop.io.SequenceFile.Writer.keyClass(Text.class);
            org.apache.hadoop.io.SequenceFile.Writer.Option valueClass =  org.apache.hadoop.io.SequenceFile.Writer.valueClass(BytesWritable.class);
            writer = org.apache.hadoop.io.SequenceFile.createWriter(
                    conf, filePath, keyClass, valueClass);
        } catch (IOException e) {
            e.printStackTrace();
        }

        Text key = new Text();
        BytesWritable val = new BytesWritable();
        long totalBytes = 0L;
        List<String> files = seq.getS3FilesPaths();
        for (String file : files) {
            S3Object s3Object = null;
            try {
                s3Object = s3Service.getObject("redborder", file);
            byte[] bytes = IOUtils.toByteArray(s3Object.getDataInputStream());
            totalBytes += bytes.length;
            val.set(bytes, 0, bytes.length);
            key.set(DigestUtils.md5Hex(bytes));
            writer.append(key, val);
            s3Object.closeDataInputStream();

            StorageObject storageObject = new S3Object();
            storageObject.setBucketName("redborder");

               String filename;
                String newFileName;
                String  pathToFile =  "rbdata/rb_malware";


                filename = file.substring((pathToFile + "/analyzing/").length());
                String [] names = filename.split("==");
                timestamp = System.currentTimeMillis();
                if(names.length>1){
                    filename=timestamp+"=="+names[names.length-1];
                }else {
                    filename=timestamp+"=="+filename;
                }


                newFileName = "rbdata/rb_malware" + "/analyzed/" + filename;

                log.log(Level.INFO, "Moving S3 file "+file+ " to "+newFileName +" for being analyzed. ");
                storageObject.setKey(newFileName);
                s3Service.renameObject("redborder", file, storageObject);
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
        try {
            writer.close();
        } catch (IOException e) {
            e.printStackTrace();
        }

        log.log(Level.INFO, "Wrote sequence file [ " + totalBytes + "B ] at: " + path + "/" + fileKey);
        hdfsURL=path + "/" + fileKey;
    }

    public String getHdfsFile(){

        return hdfsURL;

    }
}
